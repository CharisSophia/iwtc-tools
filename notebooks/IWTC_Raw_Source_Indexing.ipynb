{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c029da0e-6f8e-4eb4-a044-0a9a8ff10a5f",
   "metadata": {},
   "source": [
    "# IWTC Raw Source Indexing\n",
    "\n",
    "This notebook executes the raw source indexing workflow defined in:\n",
    "\n",
    "- `docs/raw_source_indexing_design.md`\n",
    "\n",
    "It is intended for hands-on execution and experimentation. Conceptual scope, responsibilities, and workflow design are defined in the linked design document.\n",
    "\n",
    "This notebook operates on a single world repository.\n",
    "\n",
    "A minimal example of `world_repository.yml` is provided in this repository\n",
    "under:\n",
    "\n",
    "- `data/config_examples/world_repository.yml`\n",
    "\n",
    "You may copy and adapt that example for your own world repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2058b0-9c50-411e-bdfd-eb5f63600c06",
   "metadata": {},
   "source": [
    "## Phase 0: Parameters\n",
    "\n",
    "This notebook operates on a **campaign world repository** and produces draft, machine-generated indexes for human review.\n",
    "\n",
    "In this phase, you tell the notebook **which world it is operating on** and **how broad this run should be**.\n",
    "\n",
    "At a high level:\n",
    "- You point the notebook at a world descriptor file that explains how your world’s files are organized.\n",
    "- You can optionally restrict this run to specific files or folders if you are working on a subset of material.\n",
    "- You choose whether to review discovered files interactively or process everything automatically.\n",
    "\n",
    "You do **not** need to understand internal data structures or file parsing to set these parameters.  \n",
    "The goal is simply to answer: *“What world am I indexing, and how much of it do I want to work on right now?”*\n",
    "\n",
    "The code cell below contains inline comments explaining each parameter in concrete terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b467c2b-04d7-46e3-8a00-e0bd37f493b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook run initialized at: 2026-01-08 00:18\n"
     ]
    }
   ],
   "source": [
    "# Phase 0: Parameters\n",
    "\n",
    "# Absolute path to the world_repository.yml descriptor.\n",
    "WORLD_REPOSITORY_DESCRIPTOR = (\n",
    "    \"/Users/charissophia/obsidian/Iron Wolf Trading Company/_meta/descriptors/world_repository.yml\"\n",
    ")\n",
    "\n",
    "# Optional override: use these paths instead of descriptor sources for this run.\n",
    "# Examples:\n",
    "#   OVERRIDE_PATHS = \"/Users/you/path/to/file_or_dir\"\n",
    "#   OVERRIDE_PATHS = [\"/Users/you/path/a\", \"/Users/you/path/b\"]\n",
    "OVERRIDE_PATHS = None\n",
    "\n",
    "# Selection behavior:\n",
    "#   \"PROMPT\" -> list candidates and prompt for selection\n",
    "#   \"ALL\"    -> select all candidates\n",
    "SOURCE_MODE = \"PROMPT\"\n",
    "\n",
    "# Internal run metadata (do not edit)\n",
    "from datetime import datetime\n",
    "print(f\"Notebook run initialized at: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d6408-b9bd-4cf0-a5b3-1cf8c41d2aa1",
   "metadata": {},
   "source": [
    "## Phase 1: Load and validate world descriptor\n",
    "\n",
    "Before this notebook can safely read or write anything, it must be confident that it understands the **structure of the world repository**.\n",
    "\n",
    "In this phase, the notebook:\n",
    "\n",
    "- Loads the world repository descriptor file you provided\n",
    "- Confirms that it is readable and structurally valid\n",
    "- Extracts only the information this notebook needs\n",
    "- Verifies that referenced paths actually exist and are usable\n",
    "\n",
    "This phase answers a single question:\n",
    "\n",
    "**“Can I trust this descriptor enough to proceed?”**\n",
    "\n",
    "If the answer is *no*, the notebook will stop with clear, actionable error messages explaining what needs to be fixed in the descriptor file.  \n",
    "Nothing is modified, created, or scanned until this check succeeds.\n",
    "\n",
    "This phase does **not** interpret world lore, indexing rules, or heuristics.  \n",
    "It only establishes that the filesystem layout described by the world is coherent and usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7319b2-ed33-4c54-bf08-d4c17137ed0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World repository descriptor loaded successfully: world_repository.yml\n"
     ]
    }
   ],
   "source": [
    "# Phase 1a: Load and parse world repository descriptor\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Locate descriptor file\n",
    "descriptor_path = Path(WORLD_REPOSITORY_DESCRIPTOR)\n",
    "\n",
    "if not descriptor_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"World repository descriptor file was not found.\\n\"\n",
    "        f\"Path provided:\\n  {descriptor_path}\\n\\n\"\n",
    "        \"What to do:\\n\"\n",
    "        \"- Confirm the file exists at this location or fix the Parameters cell\\n\"\n",
    "        \"- If you just edited the Parameters cell, rerun Phase 0 and then rerun this cell\\n\"\n",
    "    )\n",
    "\n",
    "# Read and parse YAML\n",
    "try:\n",
    "    with descriptor_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        world_repo = yaml.safe_load(f)\n",
    "except Exception:\n",
    "    raise ValueError(\n",
    "        \"The world repository descriptor could not be read.\\n\"\n",
    "        \"This usually indicates a YAML formatting problem.\\n\\n\"\n",
    "        f\"File:\\n  {descriptor_path}\\n\\n\"\n",
    "        \"What to do:\\n\"\n",
    "        \"- Compare the file against the example world_repository.yml\\n\"\n",
    "        \"- Paste the contents into https://www.yamllint.com/\\n\"\n",
    "        \"- Fix any reported issues, save the file, and rerun this cell\"\n",
    "    )\n",
    "\n",
    "# Validate basic structure\n",
    "if not isinstance(world_repo, dict):\n",
    "    raise ValueError(\n",
    "        \"The world repository descriptor was read, but its structure is not usable.\\n\"\n",
    "        \"The file must be a YAML mapping (top-level `name: value` entries).\\n\\n\"\n",
    "        \"What to do:\\n\"\n",
    "        \"- Compare the file against the example world_repository.yml\\n\"\n",
    "        \"- Ensure it uses clear `name: value` lines\\n\"\n",
    "        \"- Fix the file and rerun this cell\"\n",
    "    )\n",
    "\n",
    "print(f\"World repository descriptor loaded successfully: {descriptor_path.name}\")\n",
    "\n",
    "# cleanup: remove local variables\n",
    "del f, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c501c1bd-20ad-48ad-b99a-9e845794408b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor contains the required entries for this notebook.\n"
     ]
    }
   ],
   "source": [
    "# Phase 1b: Extract only the information this notebook needs (raw descriptor values)\n",
    "\n",
    "errors = []\n",
    "\n",
    "# --- required raw values ---\n",
    "DESC_WORLD_ROOT_RAW = world_repo.get(\"world_root\")\n",
    "\n",
    "# sources.read_paths can contain either:\n",
    "# - strings (backward compatible): \"- _local/recollections\"\n",
    "# - mappings: \"- path: _local/session_notes\\n  type: session_notes\"\n",
    "sources_block = world_repo.get(\"sources\")\n",
    "DESC_SOURCES_READ_PATHS_RAW = (\n",
    "    sources_block.get(\"read_paths\") if isinstance(sources_block, dict) else None\n",
    ")\n",
    "\n",
    "# working_drafts.path is required for this notebook\n",
    "working_drafts_block = world_repo.get(\"working_drafts\")\n",
    "DESC_WORKING_DRAFTS_PATH_RAW = (\n",
    "    working_drafts_block.get(\"path\") if isinstance(working_drafts_block, dict) else None\n",
    ")\n",
    "\n",
    "# --- validate presence only (not filesystem usability yet) ---\n",
    "if not DESC_WORLD_ROOT_RAW:\n",
    "    errors.append(\"Missing required entry: world_root\")\n",
    "\n",
    "if DESC_SOURCES_READ_PATHS_RAW is None:\n",
    "    errors.append(\"Missing required entry: sources.read_paths\")\n",
    "\n",
    "if not DESC_WORKING_DRAFTS_PATH_RAW:\n",
    "    errors.append(\"Missing required entry: working_drafts.path\")\n",
    "\n",
    "if errors:\n",
    "    raise ValueError(\n",
    "        \"World repository descriptor is missing required entries:\\n- \"\n",
    "        + \"\\n- \".join(errors)\n",
    "        + \"\\n\\nWhat to do:\\n\"\n",
    "          \"- Edit your world_repository.yml\\n\"\n",
    "          \"- Use the example descriptor as a reference\\n\"\n",
    "          \"- Save the file and rerun Phase 1a, then rerun this cell\\n\"\n",
    "          \"\\nNote: This check only confirms the entries exist. Path usability is validated in the next phase.\"\n",
    "    )\n",
    "\n",
    "print(\"Descriptor contains the required entries for this notebook.\")\n",
    "\n",
    "# Cleanup true temporaries\n",
    "del errors, sources_block, working_drafts_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b8db18-1c50-4eaa-ae5c-665210324ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor paths are usable for this notebook.\n",
      "world_root: /Users/charissophia/obsidian/Iron Wolf Trading Company\n",
      "sources.read_paths (resolved, no override):\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/auto_transcripts  [auto_transcripts]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/pbp_transcripts  [pbp_transcripts]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/session_notes  [session_notes]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/planning_notes  [planning_notes]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/recollections  [unknown]\n",
      "working_drafts.path: /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/machine_wip\n"
     ]
    }
   ],
   "source": [
    "# Phase 1c: Validate descriptor paths and build the validated contract variables\n",
    "#\n",
    "# Outputs (validated):\n",
    "#   WORLD_ROOT: Path\n",
    "#   DESCRIPTOR_SOURCES: list[dict]   # each {\"path\": Path, \"type\": str}\n",
    "#   WORKING_DRAFTS_PATH: Path\n",
    "#\n",
    "# Inputs (raw, from Phase 1b):\n",
    "#   DESC_WORLD_ROOT_RAW\n",
    "#   DESC_SOURCES_READ_PATHS_RAW\n",
    "#   DESC_WORKING_DRAFTS_PATH_RAW\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "errors = []\n",
    "\n",
    "# Validate world_root\n",
    "world_root = Path(DESC_WORLD_ROOT_RAW)\n",
    "\n",
    "if str(world_root).startswith(\"~\"):\n",
    "    errors.append(\"world_root: '~' is not allowed. Use a full absolute path (see the example descriptor).\")\n",
    "elif not world_root.is_absolute():\n",
    "    errors.append(\n",
    "        \"world_root must be an absolute path (macOS/Linux starts with /, Windows starts with a drive like C:\\\\). \"\n",
    "        \"See the example descriptor.\"\n",
    "    )\n",
    "elif not world_root.is_dir():\n",
    "    errors.append(f\"world_root must be an existing directory. This path does not exist: {world_root}\")\n",
    "else:\n",
    "    world_root = world_root.resolve()\n",
    "\n",
    "# Stop early if world_root is invalid (can't resolve relative paths safely)\n",
    "if errors:\n",
    "    raise ValueError(\"Descriptor path validation failed:\\n- \" + \"\\n- \".join(errors))\n",
    "\n",
    "# Validate sources.read_paths -> list of {path: Path, type: str}\n",
    "entries = DESC_SOURCES_READ_PATHS_RAW\n",
    "typed_sources = []\n",
    "\n",
    "if not isinstance(entries, list):\n",
    "    errors.append(\n",
    "        \"sources.read_paths must be a YAML list (each line starts with '-') of paths or {path,type} mappings.\"\n",
    "    )\n",
    "else:\n",
    "    for entry in entries:\n",
    "        if isinstance(entry, str):\n",
    "            path_value = entry\n",
    "            source_type = \"unknown\"\n",
    "\n",
    "        elif isinstance(entry, dict):\n",
    "            path_value = entry.get(\"path\")\n",
    "            if not path_value:\n",
    "                errors.append(\"sources.read_paths entry is missing 'path'.\")\n",
    "                continue\n",
    "            source_type = entry.get(\"type\") or \"unknown\"\n",
    "\n",
    "        else:\n",
    "            errors.append(\"sources.read_paths entries must be a path string or a {path: ..., type: ...} mapping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            p = Path(path_value)\n",
    "\n",
    "            if str(p).startswith(\"~\"):\n",
    "                errors.append(\n",
    "                    \"sources.read_paths contains a path starting with '~'. \"\n",
    "                    \"Use an absolute path or a path relative to world_root.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            if not p.is_absolute():\n",
    "                p = world_root / p\n",
    "\n",
    "            if not p.exists():\n",
    "                errors.append(f\"sources.read_paths points to a path that does not exist: {p}\")\n",
    "                continue\n",
    "\n",
    "            typed_sources.append({\"path\": p.resolve(), \"type\": source_type})\n",
    "\n",
    "        except Exception:\n",
    "            errors.append(\n",
    "                \"sources.read_paths contains a path value that cannot be interpreted as a filesystem path.\"\n",
    "            )\n",
    "\n",
    "# Validate working_drafts.path\n",
    "drafts_path = Path(DESC_WORKING_DRAFTS_PATH_RAW)\n",
    "\n",
    "if str(drafts_path).startswith(\"~\"):\n",
    "    errors.append(\"working_drafts.path cannot start with '~'. Use a full path or a path relative to world_root.\")\n",
    "else:\n",
    "    if not drafts_path.is_absolute():\n",
    "        drafts_path = world_root / drafts_path\n",
    "\n",
    "    if drafts_path.exists():\n",
    "        if not drafts_path.is_dir():\n",
    "            errors.append(\n",
    "                f\"working_drafts.path must be a directory (this process may generate multiple files): {drafts_path}\"\n",
    "            )\n",
    "        else:\n",
    "            drafts_path = drafts_path.resolve()\n",
    "    else:\n",
    "        drafts_parent = drafts_path.parent\n",
    "        if not drafts_parent.exists():\n",
    "            errors.append(f\"working_drafts.path does not exist and its parent directory is missing: {drafts_path}\")\n",
    "            errors.append(\"Action: create the parent directories or update working_drafts.path.\")\n",
    "        elif not drafts_parent.is_dir():\n",
    "            errors.append(f\"working_drafts.path parent exists but is not a directory: {drafts_parent}\")\n",
    "        else:\n",
    "            drafts_probe = drafts_parent / \".iwtc_tools_write_probe.tmp\"\n",
    "            try:\n",
    "                drafts_probe.write_text(\"test\", encoding=\"utf-8\")\n",
    "                errors.append(f\"working_drafts.path does not exist yet, but it appears creatable: {drafts_path}\")\n",
    "                errors.append(\"Action: create this directory now (recommended) or allow the tool to create it later.\")\n",
    "            except Exception:\n",
    "                errors.append(\n",
    "                    f\"working_drafts.path does not exist and may not be creatable (parent not writable): {drafts_path}\"\n",
    "                )\n",
    "                errors.append(\"Action: choose a different working_drafts.path or adjust permissions.\")\n",
    "            finally:\n",
    "                if drafts_probe.exists():\n",
    "                    drafts_probe.unlink()\n",
    "\n",
    "            # branch cleanup\n",
    "            del drafts_probe\n",
    "        del drafts_parent\n",
    "\n",
    "# Raise if any validation failed\n",
    "if errors:\n",
    "    raise ValueError(\n",
    "        \"Descriptor path validation failed:\\n- \"\n",
    "        + \"\\n- \".join(errors)\n",
    "        + f\"\\n\\nFix entries in: {Path(WORLD_REPOSITORY_DESCRIPTOR).name}\\n\"\n",
    "          \"Then rerun Phase 1a, Phase 1b, and this cell.\"\n",
    "    )\n",
    "\n",
    "# Publish validated outputs (no ENV dict)\n",
    "WORLD_ROOT = world_root\n",
    "DESCRIPTOR_SOURCES = typed_sources\n",
    "WORKING_DRAFTS_PATH = drafts_path\n",
    "\n",
    "print(\"Descriptor paths are usable for this notebook.\")\n",
    "print(f\"world_root: {WORLD_ROOT}\")\n",
    "print(\n",
    "    \"sources.read_paths (resolved, no override):\"\n",
    "    if OVERRIDE_PATHS is None\n",
    "    else \"sources.read_paths (resolved, possible override):\"\n",
    ")\n",
    "for src in DESCRIPTOR_SOURCES:\n",
    "    print(f\" - {src['path']}  [{src['type']}]\")\n",
    "print(f\"working_drafts.path: {WORKING_DRAFTS_PATH}\")\n",
    "\n",
    "# Local cleanup (validated outputs remain)\n",
    "del errors, entries, typed_sources, world_root, drafts_path, src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7758c00-3037-44b5-98a4-2dd984ca62a1",
   "metadata": {},
   "source": [
    "## Phase 2: Discover source files\n",
    "\n",
    "Before this notebook can index or analyze anything, it must determine **which files are available to work with**.\n",
    "\n",
    "In this phase, the notebook:\n",
    "- Determines which source locations to use (either override paths you provided, or the repository’s declared sources)\n",
    "- Recursively scans those locations for supported file types\n",
    "- Groups discovered files by directory for human-readable review\n",
    "- Assigns each discovered file a stable numeric ID\n",
    "- Associates each file with its declared source type (if available)\n",
    "\n",
    "This phase answers a single question:\n",
    "\n",
    "**“What source files are available for processing right now?”**\n",
    "\n",
    "If no supported files are found, the notebook will stop and explain why.  \n",
    "Nothing is read, modified, or written during discovery.\n",
    "\n",
    "Depending on your configuration:\n",
    "- If SOURCE_MODE is \"PROMPT\", you will be prompted to choose which files to process\n",
    "- Otherwise, all discovered files will be selected without prompting\n",
    "\n",
    "This phase does **not** read file contents, interpret text, or apply chunking rules.  \n",
    "It only establishes the complete, concrete list of candidate files that later phases may operate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dce55e5-1749-4380-8780-af7fb9e4f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source origin: descriptor\n",
      "Roots to scan:\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/auto_transcripts  [auto_transcripts]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/pbp_transcripts  [pbp_transcripts]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/session_notes  [session_notes]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/planning_notes  [planning_notes]\n",
      " - /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/recollections  [unknown]\n"
     ]
    }
   ],
   "source": [
    "# Phase 2a: Determine effective source roots (descriptor vs override) and report what will be scanned.\n",
    "#\n",
    "# Inputs:\n",
    "#   WORLD_ROOT\n",
    "#   DESCRIPTOR_SOURCES   # list of {\"path\": Path, \"type\": str}\n",
    "#   OVERRIDE_PATHS       # None | str | list[str]\n",
    "#\n",
    "# Outputs:\n",
    "#   EFFECTIVE_SOURCE_ROOTS  # list of {\"path\": Path, \"type\": str}\n",
    "#   SOURCE_ORIGIN           # str\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "descriptor_sources = DESCRIPTOR_SOURCES\n",
    "world_root = WORLD_ROOT\n",
    "\n",
    "# Fast lookup: inherit descriptor type for any resolved path we match.\n",
    "descriptor_type_by_path = {src[\"path\"]: (src.get(\"type\") or \"unknown\") for src in descriptor_sources}\n",
    "\n",
    "EFFECTIVE_SOURCE_ROOTS = []\n",
    "SOURCE_ORIGIN = None\n",
    "\n",
    "if OVERRIDE_PATHS is None:\n",
    "    SOURCE_ORIGIN = \"descriptor\"\n",
    "    EFFECTIVE_SOURCE_ROOTS = list(descriptor_sources)\n",
    "\n",
    "elif isinstance(OVERRIDE_PATHS, str):\n",
    "    raw = OVERRIDE_PATHS.strip()\n",
    "\n",
    "    if not raw:\n",
    "        SOURCE_ORIGIN = \"descriptor\"\n",
    "        EFFECTIVE_SOURCE_ROOTS = list(descriptor_sources)\n",
    "        print(\"Note: OVERRIDE_PATHS was blank; using descriptor sources.\")\n",
    "        del raw\n",
    "\n",
    "    elif raw.startswith(\"~\"):\n",
    "        SOURCE_ORIGIN = \"descriptor\"\n",
    "        EFFECTIVE_SOURCE_ROOTS = list(descriptor_sources)\n",
    "        print(\"Note: OVERRIDE_PATHS cannot start with '~'. Using descriptor sources.\")\n",
    "        del raw\n",
    "\n",
    "    else:\n",
    "        p = Path(raw)\n",
    "        if not p.is_absolute():\n",
    "            p = world_root / p\n",
    "        p = p.resolve()\n",
    "\n",
    "        if p.exists():\n",
    "            SOURCE_ORIGIN = \"override_path\"\n",
    "            EFFECTIVE_SOURCE_ROOTS = [{\"path\": p, \"type\": descriptor_type_by_path.get(p, \"unknown\")}]\n",
    "            del p, raw\n",
    "\n",
    "        else:\n",
    "            filtered = [s for s in descriptor_sources if (s.get(\"type\") or \"unknown\") == raw]\n",
    "            if filtered:\n",
    "                SOURCE_ORIGIN = \"descriptor_type_filter\"\n",
    "                EFFECTIVE_SOURCE_ROOTS = filtered\n",
    "            else:\n",
    "                SOURCE_ORIGIN = \"descriptor\"\n",
    "                EFFECTIVE_SOURCE_ROOTS = list(descriptor_sources)\n",
    "\n",
    "                available_types = sorted({(s.get(\"type\") or \"unknown\") for s in descriptor_sources})\n",
    "                print(\n",
    "                    f\"Note: OVERRIDE_PATHS={raw!r} was neither a valid existing path nor a known source type. \"\n",
    "                    \"Using descriptor sources.\\n\"\n",
    "                    f\"Known source types: {available_types}\\n\"\n",
    "                )\n",
    "                del available_types\n",
    "\n",
    "            del filtered, p, raw\n",
    "\n",
    "elif isinstance(OVERRIDE_PATHS, (list, tuple)):\n",
    "    roots = []\n",
    "\n",
    "    for entry in OVERRIDE_PATHS:\n",
    "        if not isinstance(entry, str):\n",
    "            raise ValueError(\n",
    "                \"OVERRIDE_PATHS list must contain only path strings.\\n\"\n",
    "                f\"Got {type(entry).__name__}: {entry!r}\"\n",
    "            )\n",
    "\n",
    "        s = entry.strip()\n",
    "        if not s:\n",
    "            del s\n",
    "            continue\n",
    "\n",
    "        if s.startswith(\"~\"):\n",
    "            raise ValueError(f\"OVERRIDE_PATHS entry cannot start with '~': {entry!r}\")\n",
    "\n",
    "        p = Path(s)\n",
    "        if not p.is_absolute():\n",
    "            p = world_root / p\n",
    "        p = p.resolve()\n",
    "\n",
    "        if not p.exists():\n",
    "            raise ValueError(f\"OVERRIDE_PATHS entry does not exist: {entry!r}\")\n",
    "\n",
    "        roots.append({\"path\": p, \"type\": descriptor_type_by_path.get(p, \"unknown\")})\n",
    "        del s, p\n",
    "\n",
    "    if not roots:\n",
    "        SOURCE_ORIGIN = \"descriptor\"\n",
    "        EFFECTIVE_SOURCE_ROOTS = list(descriptor_sources)\n",
    "        print(\"Note: OVERRIDE_PATHS list was empty; using descriptor sources.\")\n",
    "    else:\n",
    "        SOURCE_ORIGIN = \"override_paths\"\n",
    "        EFFECTIVE_SOURCE_ROOTS = roots\n",
    "\n",
    "    del roots\n",
    "\n",
    "else:\n",
    "    SOURCE_ORIGIN = \"descriptor\"\n",
    "    EFFECTIVE_SOURCE_ROOTS = list(descriptor_sources)\n",
    "    print(f\"Note: OVERRIDE_PATHS has unsupported type {type(OVERRIDE_PATHS).__name__}; using descriptor sources.\")\n",
    "\n",
    "print(f\"Source origin: {SOURCE_ORIGIN}\")\n",
    "print(\"Roots to scan:\")\n",
    "for src in EFFECTIVE_SOURCE_ROOTS:\n",
    "    print(f\" - {src['path']}  [{src.get('type', 'unknown')}]\")\n",
    "\n",
    "# Cleanup locals (keep EFFECTIVE_SOURCE_ROOTS, SOURCE_ORIGIN)\n",
    "del descriptor_sources, world_root, descriptor_type_by_path, src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4732f22-c653-4ae8-91d0-b7912746e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered supported files: 125\n"
     ]
    }
   ],
   "source": [
    "# Phase 2b: Discover supported files under EFFECTIVE_SOURCE_ROOTS\n",
    "# Produces: CANDIDATE_FILES (list of {\"id\",\"path\",\"source_type\"})\n",
    "# Keeps: CANDIDATE_FILES\n",
    "# Assumes: EFFECTIVE_SOURCE_ROOTS already resolved + typed in 2a\n",
    "\n",
    "SUPPORTED_SUFFIXES = {\".md\", \".docx\", \".txt\"}\n",
    "\n",
    "CANDIDATE_FILES = []\n",
    "next_id = 1\n",
    "\n",
    "# Sort roots so IDs are stable across runs (given same filesystem contents)\n",
    "sorted_roots = sorted(EFFECTIVE_SOURCE_ROOTS, key=lambda r: str(r[\"path\"]).lower())\n",
    "\n",
    "for root in sorted_roots:\n",
    "    root_path = root[\"path\"]\n",
    "    root_type = root.get(\"type\", \"unknown\") or \"unknown\"\n",
    "\n",
    "    if root_path.is_file():\n",
    "        if root_path.suffix.lower() in SUPPORTED_SUFFIXES:\n",
    "            CANDIDATE_FILES.append(\n",
    "                {\"id\": next_id, \"path\": root_path.resolve(), \"source_type\": root_type}\n",
    "            )\n",
    "            next_id += 1\n",
    "\n",
    "    elif root_path.is_dir():\n",
    "        # Sort children so IDs are stable within each directory\n",
    "        for p in sorted(root_path.rglob(\"*\"), key=lambda x: str(x).lower()):\n",
    "            if p.is_file() and p.suffix.lower() in SUPPORTED_SUFFIXES:\n",
    "                CANDIDATE_FILES.append(\n",
    "                    {\"id\": next_id, \"path\": p.resolve(), \"source_type\": root_type}\n",
    "                )\n",
    "                next_id += 1\n",
    "\n",
    "    else:\n",
    "        # Neither file nor dir (broken symlink or odd entry) -> ignore\n",
    "        pass\n",
    "\n",
    "    # loop cleanup (root-specific, guaranteed names)\n",
    "    del root_path, root_type\n",
    "\n",
    "print(f\"Discovered supported files: {len(CANDIDATE_FILES)}\")\n",
    "\n",
    "# TEMP: candidate list preview (turn off by setting to False)\n",
    "PRINT_CANDIDATES_PREVIEW = False\n",
    "if PRINT_CANDIDATES_PREVIEW:\n",
    "    print(\"\\nCandidate files (Phase 2b output):\\n\")\n",
    "    for item in CANDIDATE_FILES:\n",
    "        print(f\"{item['id']:>3}. {item['path']}  [type={item['source_type']}]\")\n",
    "    print()\n",
    "\n",
    "    # branch cleanup: safe even if loop is empty (item may not exist), so just don't del it.\n",
    "\n",
    "# cleanup (cell-level, guaranteed names)\n",
    "del SUPPORTED_SUFFIXES, sorted_roots, root, next_id, PRINT_CANDIDATES_PREVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fec20de-72b3-4e56-b937-197981572cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate files:\n",
      "\n",
      "/Users/charissophia/obsidian/Iron Wolf Trading Company/_local/auto_transcripts\n",
      "    1. caravan tales session 1.txt  [auto_transcripts]\n",
      "    2. caravan tales session 2.txt  [auto_transcripts]\n",
      "    3. iwtc session 000.txt  [auto_transcripts]\n",
      "    4. iwtc session 001.5.txt  [auto_transcripts]\n",
      "    5. iwtc session 001.txt  [auto_transcripts]\n",
      "    6. iwtc session 002.txt  [auto_transcripts]\n",
      "    7. iwtc session 003.txt  [auto_transcripts]\n",
      "    8. iwtc session 007.txt  [auto_transcripts]\n",
      "    9. iwtc session 008.txt  [auto_transcripts]\n",
      "   10. iwtc session 010.txt  [auto_transcripts]\n",
      "   11. iwtc session 011.txt  [auto_transcripts]\n",
      "   12. iwtc session 012.txt  [auto_transcripts]\n",
      "   13. iwtc session 013.txt  [auto_transcripts]\n",
      "   14. iwtc session 015.txt  [auto_transcripts]\n",
      "   15. iwtc session 017.txt  [auto_transcripts]\n",
      "   16. iwtc session 018.txt  [auto_transcripts]\n",
      "   17. iwtc session 019.txt  [auto_transcripts]\n",
      "   18. iwtc session 020.txt  [auto_transcripts]\n",
      "   19. iwtc session 021.txt  [auto_transcripts]\n",
      "   20. iwtc session 022.txt  [auto_transcripts]\n",
      "   21. iwtc session 023.txt  [auto_transcripts]\n",
      "   22. iwtc session 025.txt  [auto_transcripts]\n",
      "   23. iwtc session 028.1.txt  [auto_transcripts]\n",
      "   24. iwtc session 028.2.txt  [auto_transcripts]\n",
      "   25. iwtc session 030.txt  [auto_transcripts]\n",
      "   26. iwtc session 031.txt  [auto_transcripts]\n",
      "   27. iwtc session 032.5.txt  [auto_transcripts]\n",
      "   28. iwtc session 032.txt  [auto_transcripts]\n",
      "   29. iwtc session 033.txt  [auto_transcripts]\n",
      "   30. iwtc session 034.txt  [auto_transcripts]\n",
      "   31. iwtc session 035.txt  [auto_transcripts]\n",
      "   32. iwtc session 036.1.txt  [auto_transcripts]\n",
      "   33. iwtc session 036.2.txt  [auto_transcripts]\n",
      "   34. iwtc session 038.txt  [auto_transcripts]\n",
      "   35. iwtc session 039.txt  [auto_transcripts]\n",
      "   36. iwtc session 040.txt  [auto_transcripts]\n",
      "   37. iwtc session 041.txt  [auto_transcripts]\n",
      "   38. iwtc session 042.txt  [auto_transcripts]\n",
      "   39. iwtc session 043.txt  [auto_transcripts]\n",
      "   40. iwtc session 044.txt  [auto_transcripts]\n",
      "   41. iwtc session 045.txt  [auto_transcripts]\n",
      "   42. iwtc session 046.txt  [auto_transcripts]\n",
      "   43. iwtc session 047.txt  [auto_transcripts]\n",
      "   44. iwtc session 048.txt  [auto_transcripts]\n",
      "   45. iwtc session 049.txt  [auto_transcripts]\n",
      "   46. iwtc session 050.txt  [auto_transcripts]\n",
      "   47. iwtc session 051.txt  [auto_transcripts]\n",
      "   48. iwtc session 052.txt  [auto_transcripts]\n",
      "   49. iwtc session 054.txt  [auto_transcripts]\n",
      "   50. iwtc session 055.txt  [auto_transcripts]\n",
      "   51. iwtc session 056.txt  [auto_transcripts]\n",
      "   52. iwtc session 057.txt  [auto_transcripts]\n",
      "   53. iwtc session 058c.txt  [auto_transcripts]\n",
      "   54. iwtc session 059.5.txt  [auto_transcripts]\n",
      "   55. iwtc session 059.txt  [auto_transcripts]\n",
      "   56. iwtc session 060.txt  [auto_transcripts]\n",
      "   57. iwtc session 061.txt  [auto_transcripts]\n",
      "   58. iwtc session 062.txt  [auto_transcripts]\n",
      "   59. iwtc session 063.txt  [auto_transcripts]\n",
      "   60. iwtc session 064.txt  [auto_transcripts]\n",
      "   61. iwtc session 065.txt  [auto_transcripts]\n",
      "   62. iwtc session 066.txt  [auto_transcripts]\n",
      "   63. iwtc session 067.txt  [auto_transcripts]\n",
      "   64. iwtc session 068.txt  [auto_transcripts]\n",
      "   65. iwtc session 069.txt  [auto_transcripts]\n",
      "   66. iwtc session 070.txt  [auto_transcripts]\n",
      "   67. iwtc session 071.txt  [auto_transcripts]\n",
      "   68. iwtc session 072.txt  [auto_transcripts]\n",
      "   69. iwtc session 073.txt  [auto_transcripts]\n",
      "   70. iwtc session 074.txt  [auto_transcripts]\n",
      "   71. iwtc session 075.txt  [auto_transcripts]\n",
      "   72. iwtc session 077.txt  [auto_transcripts]\n",
      "   73. iwtc session 078.txt  [auto_transcripts]\n",
      "   74. iwtc session 079.txt  [auto_transcripts]\n",
      "   75. iwtc session 080.txt  [auto_transcripts]\n",
      "   76. iwtc session 081.txt  [auto_transcripts]\n",
      "   77. iwtc session 082.txt  [auto_transcripts]\n",
      "   78. iwtc session 083.txt  [auto_transcripts]\n",
      "   79. iwtc session 084.txt  [auto_transcripts]\n",
      "   80. iwtc session 085.txt  [auto_transcripts]\n",
      "   81. iwtc session 086.txt  [auto_transcripts]\n",
      "   82. iwtc session 087.txt  [auto_transcripts]\n",
      "   83. iwtc session 088.txt  [auto_transcripts]\n",
      "   84. iwtc session 089.txt  [auto_transcripts]\n",
      "   85. iwtc session 090.txt  [auto_transcripts]\n",
      "   86. iwtc session 091.txt  [auto_transcripts]\n",
      "   87. iwtc session 092.txt  [auto_transcripts]\n",
      "   88. iwtc session 093.txt  [auto_transcripts]\n",
      "   89. iwtc session 094.txt  [auto_transcripts]\n",
      "   90. iwtc session 095.txt  [auto_transcripts]\n",
      "   91. iwtc session 096.txt  [auto_transcripts]\n",
      "   92. iwtc session 097.txt  [auto_transcripts]\n",
      "   93. iwtc session 098.txt  [auto_transcripts]\n",
      "   94. iwtc session 099.txt  [auto_transcripts]\n",
      "   95. iwtc session 101.txt  [auto_transcripts]\n",
      "   96. iwtc session 102.txt  [auto_transcripts]\n",
      "   97. iwtc session 103.txt  [auto_transcripts]\n",
      "   98. iwtc session 104.txt  [auto_transcripts]\n",
      "   99. iwtc session 105.txt  [auto_transcripts]\n",
      "  100. iwtc session 106.txt  [auto_transcripts]\n",
      "  101. iwtc session 107.txt  [auto_transcripts]\n",
      "  102. iwtc session 108.txt  [auto_transcripts]\n",
      "  103. iwtc session 109.txt  [auto_transcripts]\n",
      "  104. iwtc session 110.txt  [auto_transcripts]\n",
      "  105. iwtc session 111.txt  [auto_transcripts]\n",
      "\n",
      "/Users/charissophia/obsidian/Iron Wolf Trading Company/_local/pbp_transcripts\n",
      "  106. Kavar notes.docx  [pbp_transcripts]\n",
      "  107. PbP10 - The Second Camp.md  [pbp_transcripts]\n",
      "  108. PbP11 - Lia and the Tolanites.md  [pbp_transcripts]\n",
      "  109. PbP12 - Meeting in the Vestry.md  [pbp_transcripts]\n",
      "  110. PbP13 - The Town Square Incident.md  [pbp_transcripts]\n",
      "  111. PbP14 - Recon.md  [pbp_transcripts]\n",
      "  112. PbP15 - Debrief and Safety.md  [pbp_transcripts]\n",
      "  113. PbP16 - Nightfall in Elysia.md  [pbp_transcripts]\n",
      "  114. PbP17 - Night Meetings.md  [pbp_transcripts]\n",
      "\n",
      "/Users/charissophia/obsidian/Iron Wolf Trading Company/_local/planning_notes\n",
      "  115. Allip Encounter Notes.docx  [planning_notes]\n",
      "  116. current_Dhassa staged narration.docx  [planning_notes]\n",
      "  117. current_IWTC names.docx  [planning_notes]\n",
      "  118. current_IWTC planning notes.docx  [planning_notes]\n",
      "  119. current_Kwalish.docx  [planning_notes]\n",
      "  120. Elulind map descriptions.docx  [planning_notes]\n",
      "  121. The Premature Pods Mystery.docx  [planning_notes]\n",
      "  122. The Wolfstream Situation.docx  [planning_notes]\n",
      "\n",
      "/Users/charissophia/obsidian/Iron Wolf Trading Company/_local/session_notes\n",
      "  123. current_IWTC session notes.docx  [session_notes]\n",
      "  124. IWTC session notes 1-50.docx  [session_notes]\n",
      "  125. IWTC session notes 51-100.docx  [session_notes]\n",
      "\n",
      "Total candidates: 125\n",
      "\n",
      "Enter IDs to select inputs for this run.\n",
      "Example: 1,3,5-7\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Selection:  54,114,123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected files: 3\n",
      "\n",
      "Selection summary:\n",
      " -  54. iwtc session 059.5.txt  [auto_transcripts]\n",
      " - 114. PbP17 - Night Meetings.md  [pbp_transcripts]\n",
      " - 123. current_IWTC session notes.docx  [session_notes]\n"
     ]
    }
   ],
   "source": [
    "# Phase 2c: Display candidate files and select inputs for this run.\n",
    "# Uses: CANDIDATE_FILES, SOURCE_MODE\n",
    "# Produces: SELECTED_FILES\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "if not CANDIDATE_FILES:\n",
    "    raise ValueError(\"No candidate files. Rerun Phase 2b.\")\n",
    "\n",
    "# ---- display candidates ----\n",
    "groups = defaultdict(list)\n",
    "for item in CANDIDATE_FILES:\n",
    "    groups[item[\"path\"].parent].append(item)\n",
    "\n",
    "print(\"Candidate files:\\n\")\n",
    "for parent_dir in sorted(groups.keys(), key=lambda p: str(p).lower()):\n",
    "    print(parent_dir)\n",
    "    for item in groups[parent_dir]:\n",
    "        print(f\"  {item['id']:>3}. {item['path'].name}  [{item['source_type']}]\")\n",
    "    print()\n",
    "\n",
    "print(f\"Total candidates: {len(CANDIDATE_FILES)}\\n\")\n",
    "\n",
    "# cleanup display-only locals\n",
    "del groups, item, parent_dir\n",
    "\n",
    "# ---- selection ----\n",
    "mode = str(SOURCE_MODE).strip().upper()\n",
    "\n",
    "if mode == \"ALL\":\n",
    "    SELECTED_FILES = list(CANDIDATE_FILES)\n",
    "    print(f'SOURCE_MODE=\"ALL\" -> selected all files: {len(SELECTED_FILES)}')\n",
    "\n",
    "    # branch cleanup\n",
    "    del mode\n",
    "\n",
    "elif mode == \"PROMPT\":\n",
    "    print(\"Enter IDs to select inputs for this run.\")\n",
    "    print(\"Example: 1,3,5-7\\n\")\n",
    "    selection_raw = input(\"Selection: \").strip()\n",
    "\n",
    "    if not selection_raw:\n",
    "        raise ValueError(\"No selection provided.\")\n",
    "\n",
    "    selected_ids = set()\n",
    "\n",
    "    for part in selection_raw.split(\",\"):\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "\n",
    "        if \"-\" in part:\n",
    "            a_str, b_str = part.split(\"-\", 1)\n",
    "            a = int(a_str)\n",
    "            b = int(b_str)\n",
    "            if a > b:\n",
    "                a, b = b, a\n",
    "            for v in range(a, b + 1):\n",
    "                selected_ids.add(v)\n",
    "\n",
    "            # range cleanup\n",
    "            del a_str, b_str, a, b, v\n",
    "\n",
    "        else:\n",
    "            selected_ids.add(int(part))\n",
    "\n",
    "        del part\n",
    "\n",
    "    valid_ids = {item[\"id\"] for item in CANDIDATE_FILES}\n",
    "    out_of_range = sorted(sid for sid in selected_ids if sid not in valid_ids)\n",
    "\n",
    "    if out_of_range:\n",
    "        raise ValueError(\n",
    "            f\"Invalid IDs: {out_of_range}\\n\"\n",
    "            f\"Valid range: {min(valid_ids)}–{max(valid_ids)}\"\n",
    "        )\n",
    "\n",
    "    SELECTED_FILES = [item for item in CANDIDATE_FILES if item[\"id\"] in selected_ids]\n",
    "    print(f\"Selected files: {len(SELECTED_FILES)}\")\n",
    "\n",
    "    # branch cleanup\n",
    "    del selection_raw, selected_ids, valid_ids, out_of_range, mode\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported SOURCE_MODE: {SOURCE_MODE!r}\")\n",
    "\n",
    "# ---- summary ----\n",
    "print(\"\\nSelection summary:\")\n",
    "for item in SELECTED_FILES[:10]:\n",
    "    print(f\" - {item['id']:>3}. {item['path'].name}  [{item['source_type']}]\")\n",
    "if len(SELECTED_FILES) > 10:\n",
    "    print(f\" - ... ({len(SELECTED_FILES) - 10} more)\")\n",
    "\n",
    "del item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c19c6-b8b8-4f43-9234-bdca07394c1e",
   "metadata": {},
   "source": [
    "## Phase 3: Normalize selected inputs\n",
    "\n",
    "In this phase, the notebook converts the **selected source files** into a consistent, machine-usable form.\n",
    "\n",
    "Different file formats (Markdown, plain text, Word documents) store text differently.  \n",
    "Before any indexing, chunking, or analysis can occur, those differences must be removed.\n",
    "\n",
    "In this phase, the notebook:\n",
    "\n",
    "- Opens each selected file using a format-appropriate reader\n",
    "- Extracts raw textual content without interpretation\n",
    "- Preserves line order exactly as it appears in the source file\n",
    "- Represents each file as a sequence of text lines\n",
    "- Records minimal metadata needed to trace each line back to its source file\n",
    "\n",
    "This phase performst the task:\n",
    "\n",
    "**“Create a uniform, trustworthy representation of the selected sources.”**\n",
    "\n",
    "This phase performs **no chunking, interpretation, or transformation** of content.\n",
    "Text is preserved exactly as read (including blank lines and formatting), and files are never modified on disk.\n",
    "\n",
    "The output of this phase is a normalized in-memory representation of each selected file, suitable for later chunking and indexing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73ad5429-a91e-4601-b8cf-352f88c0e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sources: 3\n",
      " - [54] txt: /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/auto_transcripts/iwtc session 059.5.txt  [auto_transcripts]  (729 lines)\n",
      " - [114] md: /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/pbp_transcripts/PbP17 - Night Meetings.md  [pbp_transcripts]  (350 lines)\n",
      " - [123] docx: /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/session_notes/current_IWTC session notes.docx  [session_notes]  (1552 lines)\n"
     ]
    }
   ],
   "source": [
    "# Phase 3: Load selected sources into memory as raw lines (preserve order and blank lines)\n",
    "\n",
    "from pathlib import Path\n",
    "import docx  # python-docx\n",
    "\n",
    "LOADED_SOURCES = []\n",
    "\n",
    "for item in SELECTED_FILES:\n",
    "    source_id = item[\"id\"]\n",
    "    path = Path(item[\"path\"])\n",
    "    source_type = item.get(\"source_type\", \"unknown\")\n",
    "\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix == \".md\":\n",
    "        file_type = \"md\"\n",
    "        text = path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "        lines = text.splitlines()\n",
    "    elif suffix == \".txt\":\n",
    "        file_type = \"txt\"\n",
    "        text = path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
    "        lines = text.splitlines()\n",
    "    elif suffix == \".docx\":\n",
    "        file_type = \"docx\"\n",
    "        doc = docx.Document(str(path))\n",
    "        lines = [p.text for p in doc.paragraphs]  # preserves blank paragraphs as \"\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type for source_id={source_id}: {path}\")\n",
    "\n",
    "    LOADED_SOURCES.append(\n",
    "        {\n",
    "            \"source_id\": source_id,\n",
    "            \"path\": path,\n",
    "            \"source_type\": source_type,\n",
    "            \"file_type\": file_type,\n",
    "            \"lines\": lines,  # list[str] in original order; blank lines preserved as \"\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Loaded sources: {len(LOADED_SOURCES)}\")\n",
    "for s in LOADED_SOURCES:\n",
    "    print(f\" - [{s['source_id']}] {s['file_type']}: {s['path']}  [{s['source_type']}]  ({len(s['lines'])} lines)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7195d60e-a65d-4aa9-a626-317b820b193d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123] docx: /Users/charissophia/obsidian/Iron Wolf Trading Company/_local/session_notes/current_IWTC session notes.docx  [session_notes]\n",
      "\n",
      "   1: \n",
      "   2: Session 101 Big Battle - 2023-04-22\n",
      "   3: We drop off Darren, Garrick, the human soldiers, and the medic team are dropped off to deal with spiders. They focus on containing and killing the spiders.\n",
      "   4: \n",
      "   5: The Folly lifts off, the illusion team starts, forming a white dragon.\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: preview a loaded source by ID\n",
    "\n",
    "PREVIEW_SOURCE_ID = 123\n",
    "PREVIEW_MAX_LINES = 5\n",
    "\n",
    "s = next((x for x in LOADED_SOURCES if x[\"source_id\"] == PREVIEW_SOURCE_ID), None)\n",
    "if s is None:\n",
    "    available = sorted(x[\"source_id\"] for x in LOADED_SOURCES)\n",
    "    raise ValueError(\n",
    "        f\"No loaded source found with source_id={PREVIEW_SOURCE_ID}. \"\n",
    "        f\"Available source_id values: {available}\"\n",
    "    )\n",
    "\n",
    "print(f\"[{s['source_id']}] {s['file_type']}: {s['path']}  [{s['source_type']}]\")\n",
    "print(\"\")\n",
    "\n",
    "for i, line in enumerate(s[\"lines\"][:PREVIEW_MAX_LINES], start=1):\n",
    "    print(f\"{i:>4}: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c17a02-41e9-4f6f-9534-cbb550a800e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eac0ce5-547d-42ae-ac25-1e7564e7a87a",
   "metadata": {},
   "source": [
    "## Vocabulary proposal (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8894e4-fa4b-4069-9803-6ce68604a006",
   "metadata": {},
   "source": [
    "## Generate draft index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40df1c-874f-4eb0-b703-e08b5f116e86",
   "metadata": {},
   "source": [
    "## Emit outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iwtc-tools)",
   "language": "python",
   "name": "iwtc-tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
